{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Wp8NQqXgQ8p"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Po-7Mpzh2R9",
        "outputId": "f6667ea1-c4b7-4e0c-9118-55b7bcb47a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in c:\\users\\viplab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in c:\\users\\viplab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mtcnn) (2.14.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\viplab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mtcnn) (4.8.1.78)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\viplab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.26.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w1UIUICgiCZf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "INPUT_IMAGE = '50.png'\n",
        "#OUTPUT_IMAGE = 'mingyu_alignment.png'\n",
        "detector = MTCNN(steps_threshold=[0.0, 0.0, 0.0])\n",
        "\n",
        "#img = cv2.cvtColor(cv2.imread(INPUT_IMAGE), cv2.COLOR_BGR2RGB)\n",
        "detector = MTCNN()\n",
        "#detections = detector.detect_faces(img)\n",
        "#detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8wRh6IFyQyJA",
        "outputId": "3e84ef61-9c9c-48ca-a1f6-94f27a74e4a5"
      },
      "outputs": [],
      "source": [
        "img_with_dets = cv2.imread(\"50.png\")\n",
        "min_conf = 0.9\n",
        "for det in detections:\n",
        "    if det['confidence'] >= min_conf:\n",
        "        x, y, width, height = det['box']\n",
        "        keypoints = det['keypoints']\n",
        "        cv2.rectangle(img_with_dets, (x,y), (x+width,y+height), (0,155,255), 2)\n",
        "        cv2.circle(img_with_dets, (keypoints['left_eye']), 2, (0,155,255), 2)\n",
        "        cv2.circle(img_with_dets, (keypoints['right_eye']), 2, (0,155,255), 2)\n",
        "        cv2.circle(img_with_dets, (keypoints['nose']), 2, (0,155,255), 2)\n",
        "        cv2.circle(img_with_dets, (keypoints['mouth_left']), 2, (0,155,255), 2)\n",
        "        cv2.circle(img_with_dets, (keypoints['mouth_right']), 2, (0,155,255), 2)\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(img_with_dets)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prPsfUK20Zct",
        "outputId": "46863811-c4a0-440a-91d6-727e674df7fe"
      },
      "outputs": [],
      "source": [
        "def landmarks(img):\n",
        "    faces = detector.detect_faces(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    face = max(faces, key=lambda x: x['confidence'])\n",
        "    return face['keypoints']\n",
        "\n",
        "def affineMatrix(lmks, scale=4):\n",
        "    nose = np.array(lmks['nose'], dtype=np.float32)\n",
        "    left_eye = np.array(lmks['left_eye'], dtype=np.float32)\n",
        "    right_eye = np.array(lmks['right_eye'], dtype=np.float32)\n",
        "    eye_width = right_eye - left_eye\n",
        "    angle = np.arctan2(eye_width[1], eye_width[0])\n",
        "    center = nose\n",
        "    alpha = np.cos(angle)\n",
        "    beta = np.sin(angle)\n",
        "    w = np.sqrt(np.sum(eye_width**2)) * scale\n",
        "    m = [[alpha, beta, -alpha * center[0] - beta * center[1] + w * 0.4],\n",
        "        [-beta, alpha, beta * center[0] - alpha * center[1] + w * 0.4]]\n",
        "    return np.array(m), (int(w), int(w))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = cv2.imread(INPUT_IMAGE)\n",
        "    mat, size = affineMatrix(landmarks(img))\n",
        "    cv2.imwrite(OUTPUT_IMAGE, cv2.warpAffine(img, mat, size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ohdRSPEm00w"
      },
      "outputs": [],
      "source": [
        "#https://github.com/Ali-Jakhar/Face-detection-using-MTCNN\n",
        "#動態顯示\n",
        "import cv2\n",
        "video = cv2.VideoCapture(\"shake_it_up_2.mp4\")\n",
        "if (video.isOpened() == False):\n",
        "    print(\"Error reading video file\")\n",
        "\n",
        "# We need to set resolutions.\n",
        "# so, convert them from float to integer.\n",
        "frame_width = int(video.get(3))\n",
        "frame_height = int(video.get(4))\n",
        "\n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "# Below VideoWriter object will create\n",
        "# a frame of above defined The output\n",
        "# is stored in 'filename.avi' file.\n",
        "result = cv2.VideoWriter('shake_it_up.avi',cv2.VideoWriter_fourcc(*'MJPG'),29, size)\n",
        "frame_num=0\n",
        "while (True):\n",
        "    ret, frame = video.read()\n",
        "    frame_num += 1\n",
        "    print(frame_num)\n",
        "    if ret == True:\n",
        "\n",
        "        location = detector.detect_faces(frame)\n",
        "        if len(location) > 0:\n",
        "            for face in location:\n",
        "                x, y, width, height = face['box']\n",
        "                x2, y2 = x + width, y + height\n",
        "                cv2.rectangle(frame, (x, y), (x2, y2), (0, 0, 255), 4)\n",
        "        result.write(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Break the loop\n",
        "    else:\n",
        "        break\n",
        "\n",
        "\n",
        "video.release()\n",
        "result.release()\n",
        "\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"The video was successfully saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "a3MTaNprklg0",
        "outputId": "a5c99992-8f11-496c-cd8d-5922266a08d7"
      },
      "outputs": [],
      "source": [
        "def faceDetection(frame):\n",
        "    detector = MTCNN()\n",
        "    boxes = detector.detect_faces(frame)\n",
        "    if boxes:\n",
        "        box = boxes[0]['box']\n",
        "        conf = boxes[0]['confidence']\n",
        "        if conf > 0.9:\n",
        "            x, y, w, h = box[0], box[1], box[2], box[3]\n",
        "            return x, y, w, h\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "-ZWvzyrakpLG",
        "outputId": "c4f78729-353c-4efc-8d83-75e48a888e7e"
      },
      "outputs": [],
      "source": [
        "frame_reader = imageio.get_reader('shake_it_up_2.mp4','ffmpeg', mode ='I')\n",
        "for frame_num, frame in enumerate(frame_reader):\n",
        "  if faceDetection(frame)!= None:\n",
        "    x, y, w, h = faceDetection(frame)\n",
        "    fig = plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(frame[y:y+h,x:x+w,:])\n",
        "    plt.show()\n",
        "    fig.savefig('output.png',bbox_inches='tight',pad_inches=0) #白色編框寬度=0\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'all'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\VIPLAB\\Desktop\\芷晏\\mtcnn.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                 cv2\u001b[39m.\u001b[39mimwrite( \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m,frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''if(faceDetection(frame)!=None):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m                x, y, w, h = faceDetection(frame)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m                fig = plt.figure()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m                plt.axis('off')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m                plt.imshow(frame[y:y+h,x:x+w,:])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m                fig.savefig('output' + str(i) +'.png',bbox_inches='tight',pad_inches=0) '''\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m cutVideo()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
            "\u001b[1;32mc:\\Users\\VIPLAB\\Desktop\\芷晏\\mtcnn.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m(frame\u001b[39m.\u001b[39;49mall()\u001b[39m!=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         cv2\u001b[39m.\u001b[39mimwrite( \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m,frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''if(faceDetection(frame)!=None):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m        x, y, w, h = faceDetection(frame)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m        fig = plt.figure()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m        plt.axis('off')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m        plt.imshow(frame[y:y+h,x:x+w,:])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/VIPLAB/Desktop/%E8%8A%B7%E6%99%8F/mtcnn.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m        fig.savefig('output' + str(i) +'.png',bbox_inches='tight',pad_inches=0) '''\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'all'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "def cutVideo():\n",
        "    i=0\n",
        "    video = cv2.VideoCapture(\"FreshOffTheBoat.mp4\")\n",
        "    if video.isOpened():\n",
        "        frame = 0\n",
        "    while(True):\n",
        "        ret,frame = video.read()\n",
        "        #cv2.imshow('video',frame)\n",
        "        c = cv2.waitKey(100)\n",
        "        \n",
        "        if c == 27: \n",
        "            break\n",
        "        i += 1\n",
        "        if i%10==0:\n",
        "            if(frame.all()!=None):\n",
        "                cv2.imwrite( str(i) + '.png',frame)\n",
        "            '''if(faceDetection(frame)!=None):\n",
        "                x, y, w, h = faceDetection(frame)\n",
        "                fig = plt.figure()\n",
        "                plt.axis('off')\n",
        "                plt.imshow(frame[y:y+h,x:x+w,:])\n",
        "                fig.savefig('output' + str(i) +'.png',bbox_inches='tight',pad_inches=0) '''\n",
        "\n",
        "\n",
        "cutVideo()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
